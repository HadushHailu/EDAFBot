{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\GoitoM\\.conda\\envs\\FAQ_chatbot\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import adam\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# load dataset from json file which is given in the folder\n",
    "with open('try1.json',encoding='utf-8') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "context = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'ተብሎ', 'የሚጠራ', 'ሲሆን', 'ይህም', 'ወይም', 'በሌሎች', 'ላይ', 'ነው', 'በ ', 'የ ', 'ከ', 'ሊሆኑ', 'ማለት', 'ይችላሉ', 'ወይ', 'ይችላል', 'በጣም', 'ከመሆን', 'የተነሳ', 'ወደ', 'ሙሉ', 'አይነት', 'ጨምሮ', 'የአንድ', 'አንድ', 'ግለሰብ', 'የሆነ', 'ሁኔታ', 'ውስጥ', 'ናቸው', 'ማለትም', 'የሚገኙ', 'በአደገኛ', 'አደገኛ', 'ወይንም', 'በአንድ', 'እንዲሁም', 'ሲሆን', 'በግዜው', 'ጨምሮ', 'ያሉ', 'ሰዎች', 'በአብዛኛውን', 'ሰው', 'ምንም', 'ሆኖ', 'ከሰው', 'ወደ', 'ከባድ', 'ምንድ', 'ምንድን', 'ምንድነው', 'ምንድናቸው', 'ነው', 'ናቸው', 'ስንል', 'ምን', 'ማለታችን', 'ማለት', 'አለው', 'የምን', 'የያዘው', 'እንዴት', 'የያዘውን', 'ሊሆን', 'የምን', 'በምን', 'የሚችል', 'ማን', 'በተለየ', 'በአብዛኛው', 'የቱን', 'የትኛው', 'እንዴት', 'አይነቶች', 'አለብን', 'ያለብን', 'ከመያዛችን', 'በፊት', 'የመያዝ', 'አጋጣሚን', 'አጋጣሚ', 'እንዳለብን', 'አሉት', 'በሰአቱ', 'በግዜው', 'ሁሉ', 'ሁሉም', 'ሆነ', 'ሆኖም', 'ሁሉንም', 'ማለት', 'ማን', 'ብቻ', 'ነገር', 'ነገሮች', 'ናቸው', 'አሁን', 'አለ', 'እስከ', 'እንኳን', 'እስከ', 'እዚሁ', 'እና', 'እንደ', 'ከ', 'ወዘተ', 'ወይም', 'ዋና', 'ይህ', 'ደግሞ', 'ጋራ', 'ግን', 'ጋር', 'ሆኖም', 'ማን', 'ለማን', 'ማነው', 'ማንማን', 'ማንን', 'ከማንኛው', 'ማንኛው', 'በማን', 'ጥቀስ', 'ግለፅ', 'ዘርዝር', 'ጥራ', 'ምን', 'ምንድን', 'የምን', 'ለምን', 'በምን', 'ወይ', 'ይሆን', 'እንደ', 'እንዴት']\n",
      "1063 documents\n",
      "126 classes ['greeting', 'መርሃ ግብሮች ፕሮግራም', 'ማስጠንቀቅያ ውጤት', 'ሜካኒካል ምህንድስና ስትሪም ', 'ሜካኒካል ምህንድስና ትርጉም', 'ምህንድስና ሚሰራበት ቦታ', 'ምህንድስና ዲፓርትመንቶች', 'ምስጋና', 'ምዝገባ ችግር', 'ሰላምታ', 'ሲቪል ምህንድስና ስትሪም ', 'ሲቪል ምህንድስና ትርጉም', 'ሲቪል ምህንድስና ጉዳት', 'ሲቪል ኢንጂነሪንግ ምሰራበት', 'ስለ ሜካኒካል ምህንድስና እውቀት', 'ስለ ሲቪል ምህንድስና እውቀት', 'ስለ አርክተክቸር ምህንድስና እውቀት', 'ስለ አድቫይዘር በይበልጥ', 'ስለ ኢንዳስትሪያል ምህንድስና እውቀት', 'ስለ ኤሌክትሪካል ምህንድስና እውቀት', 'ስለ ኬሚካል ምህንድስና እውቀት', 'ሶፍትዌር ምህንድስና ስትሪም ', 'ሶፍትዌር ምህንድስና ትርጉም', 'በትምህርት ምክንያት መባረር', 'በፈተና ወቅት መታመም', 'ትምህርት መከታተል', 'ትርፍ ጊዜ', 'አላሟላም ውጤት', 'አርክተክቸር ምህንድስና ስትሪም ', 'አርክተክቸር ምህንድስና ትርጉም', 'አድቫይዘር', 'አድቫይዘር መመደብ', 'አድቫይዘር መቀየር', 'አድቫይዘር መገናኘት', 'ኢንዳስትሪያል ምህንድስና ስትሪም ', 'ኢንዳስትሪያል ምህንድስና ትርጉም', 'ኢንጂነሪንግ', 'ኢንጂነሪንግ ለመግባት', 'ኢንጂነሪንግ ዲፓርትመንቶች', 'ኢንፎርሜሽን ስይስተም ስትሪም ', 'ኢንፎርሜሽን ስይስተም ትርጉም', 'ኤሌክትሪካል ምህንድስና ስትሪም ', 'ኤሌክትሪካል ምህንድስና ትርጉም', 'ከዩኒቨርስቲ ወደ ዩኒቨርስቲ መቀየር', 'ኬሚካል ምህንድስና ስትሪም ', 'ኬሚካል ምህንድስና ትርጉም', 'ክሬዲት ሃወር', 'ኮምፕዩተር ሳይንስ ስትሪም ', 'ኮምፕዩተር ሳይንስ ትርጉም', 'ኮርስ መድገም', 'ኮርስ መጣልና መጨመር', 'ዊዝ ድረው', 'ውጤት ማየት', 'ዝርዝር ኣለመፈለግ', 'የሜካኒካል ምህንድስና ኮርሶች', 'የሜካኒካል ምህንድስና ጉዳት', 'የሜካኒካል ምህንድስና ጥቅሞች', 'የሜካኒካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የሜካኒካል ኢንጂነሪንግ ምሰራበት', 'የሜካኒካል ኢንጂነሪንግ ስራ ዕድል', 'የምህንድስና ጉዳት', 'የምህንድስና ጥቅሞች', 'የምዝገባ ሂደት', 'የሲቪል ምህንድስና ጥቅሞች', 'የሲቪል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የሲቪል ኢንጂነሪንግ ስራ ዕድል', 'የስራ ጊዜ', 'የሶፍትዌር ምህንድስና ምሰራበት', 'የሶፍትዌር ምህንድስና ሰራተኛ ደሞዝ', 'የሶፍትዌር ምህንድስና ስራ ዕድል', 'የሶፍትዌር ምህንድስና ኮርሶች', 'የሶፍትዌር ምህንድስና ጉዳት', 'የሶፍትዌር ምህንድስና ጥቅሞች', 'የተማሪዎች ጥቅማጥቅሞች', 'የነባር መሃንዲስ ደሞዝ', 'የአርክተክቸር ምህንድስና ኮርሶች', 'የአርክተክቸር ምህንድስና ጉዳት', 'የአርክተክቸር ምህንድስና ጥቅሞች', 'የአርክተክቸር ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የአርክተክቸር ኢንጂነሪንግ ምሰራበት', 'የአርክተክቸር ኢንጂነሪንግ ስራ ዕድል', 'የኢንዳስትሪያል ምህንድስና ምሰራበት', 'የኢንዳስትሪያል ምህንድስና ኮርሶች', 'የኢንዳስትሪያል ምህንድስና ጉዳት', 'የኢንዳስትሪያል ምህንድስና ጥቅሞች', 'የኢንዳስትሪያል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኢንዳስትሪያል ኢንጂነሪንግ ስራ ዕድል', 'የኢንፎርሜሽን ስይስተም ምሰራበት', 'የኢንፎርሜሽን ስይስተም ሰራተኛ ደሞዝ', 'የኢንፎርሜሽን ስይስተም ስራ ዕድል', 'የኢንፎርሜሽን ስይስተም ኮርሶች', 'የኢንፎርሜሽን ስይስተም ጉዳት', 'የኢንፎርሜሽን ስይስተም ጥቅሞች', 'የኤሌክትሪካል ምህንድስና ኮርሶች', 'የኤሌክትሪካል ምህንድስና ጉዳት', 'የኤሌክትሪካል ምህንድስና ጥቅሞች', 'የኤሌክትሪካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኤሌክትሪካል ኢንጂነሪንግ ምሰራበት', 'የኤሌክትሪካል ኢንጂነሪንግ ስራ ዕድል', 'የኬሚካል ምህንድስና ኮርሶች', 'የኬሚካል ምህንድስና ጉዳት', 'የኬሚካል ምህንድስና ጥቅሞች', 'የኬሚካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኬሚካል ኢንጂነሪንግ ምሰራበት', 'የኬሚካል ኢንጂነሪንግ ስራ ዕድል', 'የኮምፕዩተር ሳይንስ ምሰራበት', 'የኮምፕዩተር ሳይንስ ሰራተኛ ደሞዝ', 'የኮምፕዩተር ሳይንስ ስራ ዕድል', 'የኮምፕዩተር ሳይንስ ኮርሶች', 'የኮምፕዩተር ሳይንስ ጉዳት', 'የኮምፕዩተር ሳይንስ ጥቅሞች', 'የዊዝ ድረው ጊዜ', 'የጀማሪ መሃንዲስ ደሞዝ', 'የግል አስተማሪ', 'የግዜ ሰሌዳ መቀየር', 'ደካማ ውጤት', 'ዲፓርትመንት ልውውጥ', 'ዳግም ምዝገባ', 'ግሬድ', 'ጠቅላላ እውቀት', 'ጤንነት', 'ፈተና ማራዘም', 'ፈተና ኣለመፈተን', 'ፈተና ከተራዘመ', 'ፕሪ ኢንጂነሪንግ', 'ፕሪ ኢንጂነሪንግ ጥቅም']\n",
      "457 unique stemmed words ['(', ')', '10q', 'anyon', 'ar', 'day', 'f', 'fx', 'good', 'hello', 'hi', 'how', 'i', 'is', 'ther', 'up', 'what', 'you', 'ሂደት', 'ሀል', 'ሀሳብ', 'ሀወር', 'ሀይ', 'ለመመዝገብ', 'ለመማር', 'ለመምዝገብ', 'ለመቀየር', 'ለመቀያየር', 'ለመቀጠል', 'ለመግባት', 'ለመፈተን', 'ለማስመዝገብ', 'ለምማረው', 'ለምዝገባ', 'ለምድገም', 'ለተማሪዎች', 'ለኛ', 'ለአዲስ', 'ለዲፓርትመንት', 'ሊኖረን', 'ሊኖረኝ', 'ላገኘው', 'ሌላ', 'ልያግዘኝ', 'መሀንዲስ', 'መሀንዲስ', 'መለወጥ', 'መሀንዲስ', 'መመዘኛዎች', 'መመዝገብ', 'መማሬ', 'መማር', 'መርሀ', 'መርሀ', 'መሳተፍ', 'መስራት', 'መስክ', 'መስፈርት', 'መቀየር', 'መቀያየር', 'መቕጠር', 'መቸ', 'መቼ', 'መከተል', 'መውሰድ', 'መዝናናት', 'መድገም', 'መገናኘት', 'መገኘት', 'መጠቀም', 'መጣል', 'መጣልና', 'መጨመር', 'መፈተን', 'ሚሆነው', 'ሚረዳኝ', 'ሚሰላው', 'ሚሰራው', 'ሚሰጠኝ', 'ሚሰጡ', 'ሚታየው', 'ሚያስፈልገው', 'ሚያስፈልግ', 'ሚያተኩር', 'ሚያግዘኝ', 'ሚያጠና', 'ሚያጠናው', 'ሚደረገው', 'ሚገኘው', 'ሚጠቅም', 'ሚፈቀደው', 'ማረግ', 'ማራዘም', 'ማሳውቀው', 'ማስቀየር', 'ማስጠንቀቅያ', 'ማቅረብ', 'ማየት', 'ማየው', 'ማደርገው', 'ማድረግ', 'ማገኘው', 'ማግኘት', 'ማግኝት', 'ማጠናው', 'ሜካኒካል', 'ምህንድስና', 'ምህንድስናን', 'ምመዘገበው', 'ምቀይረው', 'ምችለው', 'ምንያህል', 'ምንገናኘው', 'ምከታተልው', 'ምክንያት', 'ምዝገባ', 'ምደባ', 'ምጠይቅህ', 'ምፈተነው', 'ረዳሀኝ', 'ሩም', 'ሪፖርት', 'ሰላማት', 'ሰላም', 'ሰሌዳ', 'ሰሌዳየን', 'ሰሚስተር', 'ሰራተኛ', 'ሰአት', 'ሰአቶች', 'ሲቪል', 'ሳይንስ', 'ሳይንስን', 'ስለ', 'ስትሪም', 'ስትሪሞች', 'ስናጠና', 'ስንት', 'ስይስተም', 'ስይስተምን', 'ሶፍትዌር', 'ቀነ', 'ቀነ-ገደቡ', 'ቀነገደቡ', 'ቅደም', 'ቅድመ', 'በ1', 'በመቀለ', 'በመቐለ', 'በማስጠንቀቂያ', 'በሜካኒካል', 'በምህንድስና', 'በምህንድስናን', 'በምዝገባ', 'በምደግምበት', 'በሰሚስተር', 'በሲቪል', 'በሶፍትዌር', 'በተለያዩ', 'በትምህርት', 'በኋላ', 'በአርክተክቸር', 'በኢንዳስትሪያል', 'በኢንፎርሜሽን', 'በኤሌክትሪካል', 'በኬሚካል', 'በኮምፕዩተር', 'በኮርስ', 'በዋርኒንግ', 'በውጤቴ', 'በዩኒቨርስቲ', 'በፈተና', 'ባለኝ', 'ብህላ', 'ብኋላ', 'ብዙ', 'ብድጋሜ', 'ቦታ', 'ቦታዎች', 'ተማሪ', 'ተማሪዎች', 'ተራዝሞ', 'ተከተል', 'ተወው', 'ተግባራዊ', 'ቲ', 'ትምህርቴን', 'ትምህርት', 'ትምህርቶች', 'ትርፍ', 'ችግር', 'ችግሮች', 'ችግሮችን', 'ነህ', 'ነበር', 'ነባር', 'ነው፤', 'ንኡስ', 'ንገረኝ', 'አለብኝ', 'አለኝ', 'አሉ', 'አላሟላም', 'አላቸው', 'አልፈልግም', 'አመሰግናለሁ', 'አመት', 'አማካሪየን', 'አሪፍ', 'አርክተክቸር', 'አሳውቃለሁ', 'አሳይንመንትና', 'አስረዳኝ', 'አስተማሪ', 'አብራራልኝ', 'አችላለሁ', 'አንዴት', 'አዎ', 'አያለሁ', 'አይ', 'አደርጋለሁ', 'አዲስ', 'አድቫይዘሬን', 'አድቫይዘር', 'አድና', 'አጫጭር', 'አጭር', 'ኢ', 'ኢንኮምፕሊት', 'ኢንዳስትሪያል', 'ምህንድስና', 'ኢንፎርሜሽን', 'አለብን', 'አለብኝ', 'አሉ', 'አላሟላም', 'አላቸው', 'አማክራለሁ', 'አሳምኝ', 'አብራራልኝ', 'አይ', 'አደርክ', 'አደርጋለሁ', 'ኤሌክትሪካል', 'ኤል', 'ኤም', 'ኤች', 'እስኪ', 'እሺ', 'እችላለሁ', 'እናም', 'እንችላለን', 'እንዲመዘገብ', 'እንዳለብኝ', 'እየተማርኩ', 'እየተቸገርኩ', 'እየከበደኝ', 'እየጠናሁ', 'እድል', 'እፈልጋለሁ', 'ኦፊስ', 'ከሆነ', 'ከሆነብኝ', 'ከሆን', 'ከመጀመርያ', 'ከመጀምርያ', 'ከተማርኩ', 'ከተራዘመልኝ', 'ከተባረርኩ', 'ከተቸገርኩ', 'ከተደራረበብኝ', 'ከተፈቀድልኝ', 'ከታመምኩ', 'ከነበረ', 'ከአንድ', 'ከአድቫይዘሬ', 'ከአድቫይዘሬን', 'ከከበደኝ', 'ከዩኒቨርስቲ', 'ከዲፓርትመንት', 'ከጨረስን', 'ካለብኝ', 'ካለፈኝ', 'ካለፍኩ', 'ካላመጣሁ', 'ካላስመዘገብኩ', 'ካላስመጣሁ', 'ካላንደር', 'ካልተፈተንኩ', 'ካልቻለ', 'ካልቻልኩ', 'ካልኩሌት', 'ካመለጠኝ', 'ካመምኩ', 'ካመጣሁ', 'ካረገብኝ', 'ካራዘምኩት', 'ካስቸገረኝ', 'ካቀረብኩ', 'ካደረግኩ', 'ካጋጠመ', 'ካጋጠመኝ', 'ኬሚካል', 'ክላስ', 'ክላሽ', 'ክሬዲት', 'ክፍለ', 'ክፍል', 'ክፍሎች', 'ክፍት', 'ኮምፕዩተር', 'ኮርስ', 'ኮርሶች', 'ወቅት', 'ወቅጥ', 'ዊዝድረው', 'ዋልክ', 'ዋርኒንግ', 'ውጤቴን', 'ውጤት', 'ውጤቶቼን', 'አይነቶች', 'ዘርዝርልኝ', 'ዘርፎች', 'ዝቅተኛ', 'የመቐለ', 'የመጀመርያ', 'የመጀምርያ', 'የመጣልና', 'የመጨረሻ', 'የሚሆነው', 'የሚማረው', 'የሚረዳኝ', 'የሚሰራበት', 'የሚሰጠኝ', 'የሚሰጡ', 'የሚቻለው', 'የሚያሳይ', 'የሚያስፈልጉ', 'የሚያስፈልጉት', 'የሚደረገው', 'የሚደግመው', 'የሚጠቀሙ', 'የሜካኒካል', 'የምህንድስና', 'የምንገናኝበት', 'የምዝገባ', 'የምገባው', 'የሲቪል', 'የስራ', 'የሶፍትዌር', 'የበለጠ', 'የቢሮ', 'የተማርኩት', 'የተባረረ', 'የተዘጋጁ', 'የተፈቀድለት', 'የት', 'የትምህርቴን', 'የትምህርት', 'የትነው', 'የነባር', 'የአርክተክቸር', 'የአካዳሚክ', 'የአዲስ', 'የኢንዳስትሪያል', 'የምህንድስና', 'የኢንፎርሜሽን', 'የኤሌክትሪካል', 'የኬሚካል', 'የክላስ', 'የክፍለ', 'የኮምፕዩተር', 'የኮርስ', 'የዊዝድረው', 'የዩኒቨርስቲው', 'የጀማሪ', 'የጊዜ', 'የግል', 'የግዜ', 'የፈተና', 'የፕሪ', 'የፕሮግራም', 'የፕሮግራሞች', 'ዩኒቨርሲቲ', 'ዩኒቨርስቲ', 'ዩንቨርስቲ', 'ያህል', 'ያለብኝ', 'ያለውን', 'ያሉት', 'ያስፈልገኛል', 'ያስፈልጉኛል', 'ያስፈልጋል', 'ያቀርባል', 'ያደርጋል', 'ያጠናል', 'ይሆናል', 'ይሆናል፡፡', 'ይለኛል', 'ይለያያል', 'ይመደባል', 'ይመደብልኛል', 'ይቅርብኝ', 'ይታያል', 'ይቻላል', 'ይቻላልን', 'ይከሰታል', 'ይዞታ', 'ይደረጋል', 'ይጠቅመኛል', 'ይጠቅማል', 'ይፈቀዳል', 'ደህና', 'ደሞዝ', 'ደስ', 'ደና', 'ዲጋሜ', 'ዲፓርትመንት', 'ዲፓርትመንቶች', 'ዳግም', 'ድሮፕ', 'ድጋሜ', 'ጀማሪ', 'ገደብ', 'ጉዳቱን', 'ጉዳት', 'ጉዳቶች', 'ጉድለቶችን', 'ጊዜ', 'ግለፅልኝ', 'ግለፅልኝ', 'ግሬዴን', 'ግሬድ', 'ግብሮች', 'ግንኙነት', 'ግጭት', 'ጠቀሜታ', 'ጠቀሜታው', 'ጠቀሜታዎችን', 'ጠቃሚ', 'ጥሩ', 'ጥቅሙ', 'ጥቅም', 'ጥቅሞች', 'ጥቅሞችን', 'ጥናት', 'ፈልጌ', 'ፈተና', 'ፈተናየን', 'ፈተና፣', 'ፋኩልቲ', 'ፋካሊቲ', 'ፋይናል', 'ፕሪ', 'ፕሮግራም', 'ፕሮግራሞች']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "\n",
    "f=open(\"stopwords.txt\",'r',encoding=\"utf-8\")\n",
    "#stopword = ['?'] \n",
    "ignore_word=f.read().splitlines()\n",
    "f.close()\n",
    "ignore_words.extend(ignore_word)\n",
    "print (ignore_words)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\tmodified_word_list=[word for word in text if not word  in ignore_words]\n",
    "\treturn modified_word_list\n",
    "\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words]\n",
    "words= remove_stopwords(words)\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "words =[i.replace('ኀ','ሀ').replace('ሐ','ሀ').replace('ሃ','ሀ').replace('ኃ','ሀ').replace('ሓ','ሀ').replace('ኁ','ሁ').replace('ሑ','ሁ').replace('ሒ','ሂ').replace('ኂ','ሂ').replace('ኄ','ሄ').replace('ሔ','ሄ').replace('ሕ','ህ').replace('ኅ','ህ').replace('ሖ','ሆ').replace('ኆ','ሆ').replace('ጸ','ፀ').replace('ጹ','ፁ').replace('ጺ','ፂ').replace('ጻ','ፃ').replace('ጼ','ፄ').replace('ጽ','ፅ').replace('ጾ','ፆ').replace('ቸ,','ቼ').replace('ሸ','ሼ').replace('ዬ','የ').replace('ዉ','ው').replace('ሓ','ሀ').replace('ሠ','ሰ').replace('ሡ','ሱ').replace('ሢ','ሲ').replace('ሣ','ሳ').replace('ሤ','ሴ').replace('ሥ','ስ').replace('ሦ','ሶ').replace('ዐ','አ').replace('ዑ','ኡ').replace('ዒ','ኢ').replace('ዓ','አ').replace('ኣ','አ').replace('ዔ','ኤ').replace('ዕ','እ').replace('ዖ','ኦ') for i in words]\n",
    "words =[i.replace('መካኒካል','ሜካኒካል').replace('ኢንጂነሪንግ','ምህንድስና').replace('ሰፍትዌር','ሶፍትዌር').replace('ሲስተም','ስይስተም').replace('ከሚካል','ኬሚካል').replace('ደምወዝ','ደሞዝ').replace('ዶሞዝ','ደሞዝ').replace('አርኪተክቸር','አርክተክቸር').replace('ኢሌክትሪካል','ኤሌክትሪካል').replace('ኮምፒተር','ኮምፕዩተር').replace('ሳይነስ','ሳይንስ').replace('ኢንፎርመሽን','ኢንፎርሜሽን').replace('ኢንዱስትርያል','ኢንዳስትሪያል').replace('ኢንዱስትሪያል','ኢንዳስትሪያል').replace('መሃንዲስ','መሀንድስ') for i in words]\n",
    "\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "x = list(training[:,0])\n",
    "y = list(training[:,1])\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "train_x,test_x,train_y,test_y=tts(x, y, test_size=.2, random_state=42)\n",
    "val_x=np.array(test_x)\n",
    "val_y=np.array(test_y)    \n",
    "    \n",
    "    \n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "train_x,test_x,train_y,test_y=tts(x, y, test_size=.2, random_state=42)\n",
    "\n",
    "val_x=np.array(test_x)\n",
    "val_y=np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n",
      "850\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "x = list(training[:,0])\n",
    "y = list(training[:,1])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "train_x,test_x,train_y,test_y=tts(x, y, test_size=.2, random_state=42)\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(test_y))\n",
    "\n",
    "val_x=np.array(test_x)\n",
    "val_y=np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 128)               58624     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 126)               8190      \n",
      "=================================================================\n",
      "Total params: 75,070\n",
      "Trainable params: 75,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 4 layers. First layer equals to the number of input features, 2 hidden layers with 128 & 64 hidden neurons \n",
    "# and 4th output layer contains number of neurons equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128,input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Compile model. with Adam Optimizer and learning rate 0.0001 which gives good results for this model\n",
    "Adam = adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history=model.fit(np.array(train_x), np.array(train_y), epochs=150, batch_size=8,validation_data=(val_x,val_y), verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "print(len(train_x[0]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 850 samples, validate on 213 samples\n",
      "Epoch 1/150\n",
      "850/850 [==============================] - 5s 6ms/step - loss: 4.8316 - acc: 0.0141 - val_loss: 4.8049 - val_acc: 0.0235\n",
      "Epoch 2/150\n",
      "850/850 [==============================] - 1s 942us/step - loss: 4.7903 - acc: 0.0282 - val_loss: 4.7711 - val_acc: 0.0329\n",
      "Epoch 3/150\n",
      "850/850 [==============================] - 1s 963us/step - loss: 4.7472 - acc: 0.0482 - val_loss: 4.7332 - val_acc: 0.0423\n",
      "Epoch 4/150\n",
      "850/850 [==============================] - 1s 925us/step - loss: 4.6986 - acc: 0.0729 - val_loss: 4.6888 - val_acc: 0.0751\n",
      "Epoch 5/150\n",
      "850/850 [==============================] - 1s 961us/step - loss: 4.6447 - acc: 0.1271 - val_loss: 4.6384 - val_acc: 0.0986\n",
      "Epoch 6/150\n",
      "850/850 [==============================] - 1s 948us/step - loss: 4.5833 - acc: 0.1282 - val_loss: 4.5775 - val_acc: 0.1268\n",
      "Epoch 7/150\n",
      "850/850 [==============================] - 1s 942us/step - loss: 4.5060 - acc: 0.1518 - val_loss: 4.5063 - val_acc: 0.1315\n",
      "Epoch 8/150\n",
      "850/850 [==============================] - 1s 961us/step - loss: 4.4180 - acc: 0.1682 - val_loss: 4.4276 - val_acc: 0.1315\n",
      "Epoch 9/150\n",
      "850/850 [==============================] - 1s 960us/step - loss: 4.3269 - acc: 0.1647 - val_loss: 4.3422 - val_acc: 0.1362\n",
      "Epoch 10/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 4.2247 - acc: 0.1812 - val_loss: 4.2567 - val_acc: 0.1455\n",
      "Epoch 11/150\n",
      "850/850 [==============================] - 1s 960us/step - loss: 4.1221 - acc: 0.1906 - val_loss: 4.1688 - val_acc: 0.1596\n",
      "Epoch 12/150\n",
      "850/850 [==============================] - 1s 941us/step - loss: 4.0248 - acc: 0.2165 - val_loss: 4.0815 - val_acc: 0.1784\n",
      "Epoch 13/150\n",
      "850/850 [==============================] - 1s 960us/step - loss: 3.9120 - acc: 0.2259 - val_loss: 3.9908 - val_acc: 0.2113\n",
      "Epoch 14/150\n",
      "850/850 [==============================] - 1s 912us/step - loss: 3.8055 - acc: 0.2588 - val_loss: 3.8986 - val_acc: 0.2582\n",
      "Epoch 15/150\n",
      "850/850 [==============================] - 1s 949us/step - loss: 3.6970 - acc: 0.2871 - val_loss: 3.8021 - val_acc: 0.2817\n",
      "Epoch 16/150\n",
      "850/850 [==============================] - 1s 943us/step - loss: 3.5767 - acc: 0.3424 - val_loss: 3.7027 - val_acc: 0.3146\n",
      "Epoch 17/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 3.4756 - acc: 0.3612 - val_loss: 3.5990 - val_acc: 0.3286\n",
      "Epoch 18/150\n",
      "850/850 [==============================] - 1s 938us/step - loss: 3.3436 - acc: 0.3918 - val_loss: 3.4966 - val_acc: 0.3380\n",
      "Epoch 19/150\n",
      "850/850 [==============================] - 1s 955us/step - loss: 3.2307 - acc: 0.4224 - val_loss: 3.3978 - val_acc: 0.3568\n",
      "Epoch 20/150\n",
      "850/850 [==============================] - 1s 937us/step - loss: 3.1196 - acc: 0.4294 - val_loss: 3.2939 - val_acc: 0.3756\n",
      "Epoch 21/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 3.0061 - acc: 0.4435 - val_loss: 3.1911 - val_acc: 0.3803\n",
      "Epoch 22/150\n",
      "850/850 [==============================] - 1s 940us/step - loss: 2.8788 - acc: 0.4659 - val_loss: 3.0891 - val_acc: 0.4131\n",
      "Epoch 23/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 2.7738 - acc: 0.4788 - val_loss: 2.9911 - val_acc: 0.4178\n",
      "Epoch 24/150\n",
      "850/850 [==============================] - 1s 933us/step - loss: 2.6739 - acc: 0.5118 - val_loss: 2.8936 - val_acc: 0.4554\n",
      "Epoch 25/150\n",
      "850/850 [==============================] - 1s 948us/step - loss: 2.5714 - acc: 0.5153 - val_loss: 2.7984 - val_acc: 0.4742\n",
      "Epoch 26/150\n",
      "850/850 [==============================] - 1s 921us/step - loss: 2.4556 - acc: 0.5412 - val_loss: 2.7098 - val_acc: 0.5070\n",
      "Epoch 27/150\n",
      "850/850 [==============================] - 1s 949us/step - loss: 2.3760 - acc: 0.5353 - val_loss: 2.6233 - val_acc: 0.5446\n",
      "Epoch 28/150\n",
      "850/850 [==============================] - 1s 934us/step - loss: 2.2824 - acc: 0.5694 - val_loss: 2.5389 - val_acc: 0.5634\n",
      "Epoch 29/150\n",
      "850/850 [==============================] - 1s 940us/step - loss: 2.1937 - acc: 0.5788 - val_loss: 2.4574 - val_acc: 0.5634\n",
      "Epoch 30/150\n",
      "850/850 [==============================] - 1s 922us/step - loss: 2.1015 - acc: 0.6165 - val_loss: 2.3800 - val_acc: 0.5681\n",
      "Epoch 31/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 2.0266 - acc: 0.6259 - val_loss: 2.3039 - val_acc: 0.5822\n",
      "Epoch 32/150\n",
      "850/850 [==============================] - 1s 936us/step - loss: 1.9471 - acc: 0.6388 - val_loss: 2.2329 - val_acc: 0.5962\n",
      "Epoch 33/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 1.8591 - acc: 0.6682 - val_loss: 2.1631 - val_acc: 0.6197\n",
      "Epoch 34/150\n",
      "850/850 [==============================] - 1s 941us/step - loss: 1.7962 - acc: 0.6729 - val_loss: 2.0961 - val_acc: 0.6197\n",
      "Epoch 35/150\n",
      "850/850 [==============================] - 1s 920us/step - loss: 1.7160 - acc: 0.6906 - val_loss: 2.0323 - val_acc: 0.6244\n",
      "Epoch 36/150\n",
      "850/850 [==============================] - 1s 922us/step - loss: 1.6556 - acc: 0.7047 - val_loss: 1.9709 - val_acc: 0.6338\n",
      "Epoch 37/150\n",
      "850/850 [==============================] - 1s 908us/step - loss: 1.5856 - acc: 0.7224 - val_loss: 1.9093 - val_acc: 0.6526\n",
      "Epoch 38/150\n",
      "850/850 [==============================] - 1s 940us/step - loss: 1.5363 - acc: 0.7376 - val_loss: 1.8525 - val_acc: 0.6526\n",
      "Epoch 39/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 1.4804 - acc: 0.7388 - val_loss: 1.7951 - val_acc: 0.6573\n",
      "Epoch 40/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 1.4228 - acc: 0.7588 - val_loss: 1.7427 - val_acc: 0.6573\n",
      "Epoch 41/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 1.3545 - acc: 0.7682 - val_loss: 1.6905 - val_acc: 0.6620\n",
      "Epoch 42/150\n",
      "850/850 [==============================] - 1s 946us/step - loss: 1.3066 - acc: 0.7953 - val_loss: 1.6395 - val_acc: 0.6620\n",
      "Epoch 43/150\n",
      "850/850 [==============================] - 1s 950us/step - loss: 1.2510 - acc: 0.8035 - val_loss: 1.5874 - val_acc: 0.6901\n",
      "Epoch 44/150\n",
      "850/850 [==============================] - 1s 906us/step - loss: 1.2054 - acc: 0.8024 - val_loss: 1.5409 - val_acc: 0.7371\n",
      "Epoch 45/150\n",
      "850/850 [==============================] - 1s 925us/step - loss: 1.1784 - acc: 0.8176 - val_loss: 1.4944 - val_acc: 0.7371\n",
      "Epoch 46/150\n",
      "850/850 [==============================] - 1s 925us/step - loss: 1.1188 - acc: 0.8224 - val_loss: 1.4493 - val_acc: 0.7371\n",
      "Epoch 47/150\n",
      "850/850 [==============================] - 1s 900us/step - loss: 1.0841 - acc: 0.8341 - val_loss: 1.4061 - val_acc: 0.7418\n",
      "Epoch 48/150\n",
      "850/850 [==============================] - 1s 922us/step - loss: 1.0286 - acc: 0.8388 - val_loss: 1.3627 - val_acc: 0.7559\n",
      "Epoch 49/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 0.9934 - acc: 0.8506 - val_loss: 1.3215 - val_acc: 0.7606\n",
      "Epoch 50/150\n",
      "850/850 [==============================] - 1s 996us/step - loss: 0.9611 - acc: 0.8459 - val_loss: 1.2828 - val_acc: 0.7746\n",
      "Epoch 51/150\n",
      "850/850 [==============================] - 1s 939us/step - loss: 0.9253 - acc: 0.8635 - val_loss: 1.2436 - val_acc: 0.7746\n",
      "Epoch 52/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 0.8938 - acc: 0.8671 - val_loss: 1.2109 - val_acc: 0.7793\n",
      "Epoch 53/150\n",
      "850/850 [==============================] - 1s 899us/step - loss: 0.8562 - acc: 0.8753 - val_loss: 1.1746 - val_acc: 0.7934\n",
      "Epoch 54/150\n",
      "850/850 [==============================] - 1s 898us/step - loss: 0.8140 - acc: 0.8906 - val_loss: 1.1400 - val_acc: 0.7981\n",
      "Epoch 55/150\n",
      "850/850 [==============================] - 1s 902us/step - loss: 0.7792 - acc: 0.8859 - val_loss: 1.1077 - val_acc: 0.7981\n",
      "Epoch 56/150\n",
      "850/850 [==============================] - 1s 896us/step - loss: 0.7624 - acc: 0.8835 - val_loss: 1.0764 - val_acc: 0.7981\n",
      "Epoch 57/150\n",
      "850/850 [==============================] - 1s 882us/step - loss: 0.7349 - acc: 0.8941 - val_loss: 1.0433 - val_acc: 0.8075\n",
      "Epoch 58/150\n",
      "850/850 [==============================] - 1s 886us/step - loss: 0.7093 - acc: 0.9000 - val_loss: 1.0130 - val_acc: 0.8075\n",
      "Epoch 59/150\n",
      "850/850 [==============================] - 1s 896us/step - loss: 0.6905 - acc: 0.9012 - val_loss: 0.9869 - val_acc: 0.8122\n",
      "Epoch 60/150\n",
      "850/850 [==============================] - 1s 890us/step - loss: 0.6549 - acc: 0.9071 - val_loss: 0.9609 - val_acc: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 0.6293 - acc: 0.9106 - val_loss: 0.9340 - val_acc: 0.8169\n",
      "Epoch 62/150\n",
      "850/850 [==============================] - 1s 918us/step - loss: 0.5994 - acc: 0.9165 - val_loss: 0.9085 - val_acc: 0.8216\n",
      "Epoch 63/150\n",
      "850/850 [==============================] - 1s 942us/step - loss: 0.5832 - acc: 0.9200 - val_loss: 0.8828 - val_acc: 0.8263\n",
      "Epoch 64/150\n",
      "850/850 [==============================] - 1s 939us/step - loss: 0.5646 - acc: 0.9200 - val_loss: 0.8613 - val_acc: 0.8357\n",
      "Epoch 65/150\n",
      "850/850 [==============================] - 1s 940us/step - loss: 0.5482 - acc: 0.9235 - val_loss: 0.8382 - val_acc: 0.8451\n",
      "Epoch 66/150\n",
      "850/850 [==============================] - 1s 921us/step - loss: 0.5351 - acc: 0.9235 - val_loss: 0.8153 - val_acc: 0.8545\n",
      "Epoch 67/150\n",
      "850/850 [==============================] - 1s 907us/step - loss: 0.5037 - acc: 0.9341 - val_loss: 0.7949 - val_acc: 0.8545\n",
      "Epoch 68/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.4938 - acc: 0.9306 - val_loss: 0.7754 - val_acc: 0.8732\n",
      "Epoch 69/150\n",
      "850/850 [==============================] - 1s 919us/step - loss: 0.4665 - acc: 0.9388 - val_loss: 0.7575 - val_acc: 0.8779\n",
      "Epoch 70/150\n",
      "850/850 [==============================] - 1s 908us/step - loss: 0.4500 - acc: 0.9471 - val_loss: 0.7386 - val_acc: 0.8920\n",
      "Epoch 71/150\n",
      "850/850 [==============================] - 1s 910us/step - loss: 0.4336 - acc: 0.9435 - val_loss: 0.7216 - val_acc: 0.8920\n",
      "Epoch 72/150\n",
      "850/850 [==============================] - 1s 908us/step - loss: 0.4247 - acc: 0.9447 - val_loss: 0.7041 - val_acc: 0.8967\n",
      "Epoch 73/150\n",
      "850/850 [==============================] - 1s 902us/step - loss: 0.4093 - acc: 0.9482 - val_loss: 0.6883 - val_acc: 0.9014\n",
      "Epoch 74/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.3868 - acc: 0.9518 - val_loss: 0.6726 - val_acc: 0.9014\n",
      "Epoch 75/150\n",
      "850/850 [==============================] - 1s 903us/step - loss: 0.3861 - acc: 0.9435 - val_loss: 0.6601 - val_acc: 0.9014\n",
      "Epoch 76/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.3758 - acc: 0.9482 - val_loss: 0.6446 - val_acc: 0.9014\n",
      "Epoch 77/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.3601 - acc: 0.9553 - val_loss: 0.6315 - val_acc: 0.9014\n",
      "Epoch 78/150\n",
      "850/850 [==============================] - 1s 918us/step - loss: 0.3528 - acc: 0.9518 - val_loss: 0.6203 - val_acc: 0.9014\n",
      "Epoch 79/150\n",
      "850/850 [==============================] - 1s 901us/step - loss: 0.3300 - acc: 0.9541 - val_loss: 0.6091 - val_acc: 0.9061\n",
      "Epoch 80/150\n",
      "850/850 [==============================] - 1s 920us/step - loss: 0.3226 - acc: 0.9612 - val_loss: 0.5992 - val_acc: 0.9061\n",
      "Epoch 81/150\n",
      "850/850 [==============================] - 1s 902us/step - loss: 0.3164 - acc: 0.9541 - val_loss: 0.5888 - val_acc: 0.9061\n",
      "Epoch 82/150\n",
      "850/850 [==============================] - 1s 903us/step - loss: 0.3109 - acc: 0.9471 - val_loss: 0.5779 - val_acc: 0.9061\n",
      "Epoch 83/150\n",
      "850/850 [==============================] - 1s 921us/step - loss: 0.2905 - acc: 0.9588 - val_loss: 0.5689 - val_acc: 0.9202\n",
      "Epoch 84/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.2797 - acc: 0.9576 - val_loss: 0.5601 - val_acc: 0.9249\n",
      "Epoch 85/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 0.2776 - acc: 0.9600 - val_loss: 0.5529 - val_acc: 0.9296\n",
      "Epoch 86/150\n",
      "850/850 [==============================] - 1s 899us/step - loss: 0.2608 - acc: 0.9659 - val_loss: 0.5451 - val_acc: 0.9296\n",
      "Epoch 87/150\n",
      "850/850 [==============================] - 1s 907us/step - loss: 0.2554 - acc: 0.9647 - val_loss: 0.5380 - val_acc: 0.9296\n",
      "Epoch 88/150\n",
      "850/850 [==============================] - 1s 919us/step - loss: 0.2466 - acc: 0.9647 - val_loss: 0.5299 - val_acc: 0.9343\n",
      "Epoch 89/150\n",
      "850/850 [==============================] - 1s 906us/step - loss: 0.2478 - acc: 0.9624 - val_loss: 0.5234 - val_acc: 0.9343\n",
      "Epoch 90/150\n",
      "850/850 [==============================] - 1s 914us/step - loss: 0.2333 - acc: 0.9694 - val_loss: 0.5152 - val_acc: 0.9343\n",
      "Epoch 91/150\n",
      "850/850 [==============================] - 1s 890us/step - loss: 0.2313 - acc: 0.9635 - val_loss: 0.5096 - val_acc: 0.9343\n",
      "Epoch 92/150\n",
      "850/850 [==============================] - 1s 902us/step - loss: 0.2200 - acc: 0.9671 - val_loss: 0.5034 - val_acc: 0.9343\n",
      "Epoch 93/150\n",
      "850/850 [==============================] - 1s 895us/step - loss: 0.2262 - acc: 0.9647 - val_loss: 0.4958 - val_acc: 0.9343\n",
      "Epoch 94/150\n",
      "850/850 [==============================] - 1s 905us/step - loss: 0.2071 - acc: 0.9729 - val_loss: 0.4926 - val_acc: 0.9343\n",
      "Epoch 95/150\n",
      "850/850 [==============================] - 1s 903us/step - loss: 0.2032 - acc: 0.9729 - val_loss: 0.4874 - val_acc: 0.9296\n",
      "Epoch 96/150\n",
      "850/850 [==============================] - 1s 899us/step - loss: 0.2083 - acc: 0.9694 - val_loss: 0.4838 - val_acc: 0.9343\n",
      "Epoch 97/150\n",
      "850/850 [==============================] - 1s 904us/step - loss: 0.1985 - acc: 0.9694 - val_loss: 0.4798 - val_acc: 0.9296\n",
      "Epoch 98/150\n",
      "850/850 [==============================] - 1s 899us/step - loss: 0.1908 - acc: 0.9718 - val_loss: 0.4744 - val_acc: 0.9249\n",
      "Epoch 99/150\n",
      "850/850 [==============================] - 1s 896us/step - loss: 0.1888 - acc: 0.9765 - val_loss: 0.4726 - val_acc: 0.9249\n",
      "Epoch 100/150\n",
      "850/850 [==============================] - 1s 899us/step - loss: 0.1900 - acc: 0.9647 - val_loss: 0.4688 - val_acc: 0.9249\n",
      "Epoch 101/150\n",
      "850/850 [==============================] - 1s 893us/step - loss: 0.1759 - acc: 0.9729 - val_loss: 0.4630 - val_acc: 0.9249\n",
      "Epoch 102/150\n",
      "850/850 [==============================] - 1s 897us/step - loss: 0.1751 - acc: 0.9729 - val_loss: 0.4593 - val_acc: 0.9249\n",
      "Epoch 103/150\n",
      "850/850 [==============================] - 1s 885us/step - loss: 0.1666 - acc: 0.9788 - val_loss: 0.4557 - val_acc: 0.9249\n",
      "Epoch 104/150\n",
      "850/850 [==============================] - 1s 900us/step - loss: 0.1550 - acc: 0.9765 - val_loss: 0.4504 - val_acc: 0.9249\n",
      "Epoch 105/150\n",
      "850/850 [==============================] - 1s 901us/step - loss: 0.1578 - acc: 0.9753 - val_loss: 0.4473 - val_acc: 0.9202\n",
      "Epoch 106/150\n",
      "850/850 [==============================] - 1s 906us/step - loss: 0.1568 - acc: 0.9741 - val_loss: 0.4445 - val_acc: 0.9202\n",
      "Epoch 107/150\n",
      "850/850 [==============================] - 1s 896us/step - loss: 0.1485 - acc: 0.9776 - val_loss: 0.4425 - val_acc: 0.9249\n",
      "Epoch 108/150\n",
      "850/850 [==============================] - 1s 888us/step - loss: 0.1513 - acc: 0.9776 - val_loss: 0.4403 - val_acc: 0.9155\n",
      "Epoch 109/150\n",
      "850/850 [==============================] - 1s 901us/step - loss: 0.1443 - acc: 0.9776 - val_loss: 0.4385 - val_acc: 0.9155\n",
      "Epoch 110/150\n",
      "850/850 [==============================] - 1s 890us/step - loss: 0.1376 - acc: 0.9812 - val_loss: 0.4380 - val_acc: 0.9249\n",
      "Epoch 111/150\n",
      "850/850 [==============================] - 1s 893us/step - loss: 0.1373 - acc: 0.9765 - val_loss: 0.4361 - val_acc: 0.9249\n",
      "Epoch 112/150\n",
      "850/850 [==============================] - 1s 904us/step - loss: 0.1327 - acc: 0.9812 - val_loss: 0.4356 - val_acc: 0.9249\n",
      "Epoch 113/150\n",
      "850/850 [==============================] - 1s 884us/step - loss: 0.1250 - acc: 0.9800 - val_loss: 0.4323 - val_acc: 0.9296\n",
      "Epoch 114/150\n",
      "850/850 [==============================] - 1s 898us/step - loss: 0.1331 - acc: 0.9788 - val_loss: 0.4287 - val_acc: 0.9296\n",
      "Epoch 115/150\n",
      "850/850 [==============================] - 1s 887us/step - loss: 0.1346 - acc: 0.9729 - val_loss: 0.4278 - val_acc: 0.9296\n",
      "Epoch 116/150\n",
      "850/850 [==============================] - 1s 897us/step - loss: 0.1320 - acc: 0.9765 - val_loss: 0.4257 - val_acc: 0.9296\n",
      "Epoch 117/150\n",
      "850/850 [==============================] - 1s 870us/step - loss: 0.1197 - acc: 0.9800 - val_loss: 0.4237 - val_acc: 0.9296\n",
      "Epoch 118/150\n",
      "850/850 [==============================] - 1s 885us/step - loss: 0.1194 - acc: 0.9800 - val_loss: 0.4241 - val_acc: 0.9343\n",
      "Epoch 119/150\n",
      "850/850 [==============================] - 1s 949us/step - loss: 0.1292 - acc: 0.9753 - val_loss: 0.4219 - val_acc: 0.9296\n",
      "Epoch 120/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 0.1086 - acc: 0.9847 - val_loss: 0.4219 - val_acc: 0.9296\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 1s 939us/step - loss: 0.1089 - acc: 0.9800 - val_loss: 0.4212 - val_acc: 0.9296\n",
      "Epoch 122/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.1099 - acc: 0.9776 - val_loss: 0.4200 - val_acc: 0.9343\n",
      "Epoch 123/150\n",
      "850/850 [==============================] - 1s 940us/step - loss: 0.1106 - acc: 0.9800 - val_loss: 0.4178 - val_acc: 0.9296\n",
      "Epoch 124/150\n",
      "850/850 [==============================] - 1s 922us/step - loss: 0.1084 - acc: 0.9776 - val_loss: 0.4151 - val_acc: 0.9296\n",
      "Epoch 125/150\n",
      "850/850 [==============================] - 1s 921us/step - loss: 0.1061 - acc: 0.9800 - val_loss: 0.4146 - val_acc: 0.9343\n",
      "Epoch 126/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.1091 - acc: 0.9753 - val_loss: 0.4146 - val_acc: 0.9390\n",
      "Epoch 127/150\n",
      "850/850 [==============================] - 1s 906us/step - loss: 0.1009 - acc: 0.9812 - val_loss: 0.4110 - val_acc: 0.9390\n",
      "Epoch 128/150\n",
      "850/850 [==============================] - 1s 919us/step - loss: 0.1098 - acc: 0.9753 - val_loss: 0.4123 - val_acc: 0.9390\n",
      "Epoch 129/150\n",
      "850/850 [==============================] - 1s 922us/step - loss: 0.1013 - acc: 0.9800 - val_loss: 0.4109 - val_acc: 0.9390\n",
      "Epoch 130/150\n",
      "850/850 [==============================] - 1s 920us/step - loss: 0.0980 - acc: 0.9788 - val_loss: 0.4106 - val_acc: 0.9390\n",
      "Epoch 131/150\n",
      "850/850 [==============================] - 1s 923us/step - loss: 0.0969 - acc: 0.9765 - val_loss: 0.4110 - val_acc: 0.9343\n",
      "Epoch 132/150\n",
      "850/850 [==============================] - 1s 924us/step - loss: 0.0900 - acc: 0.9824 - val_loss: 0.4098 - val_acc: 0.9390\n",
      "Epoch 133/150\n",
      "850/850 [==============================] - 1s 921us/step - loss: 0.0947 - acc: 0.9812 - val_loss: 0.4085 - val_acc: 0.9390\n",
      "Epoch 134/150\n",
      "850/850 [==============================] - 1s 903us/step - loss: 0.0904 - acc: 0.9800 - val_loss: 0.4084 - val_acc: 0.9343\n",
      "Epoch 135/150\n",
      "850/850 [==============================] - 1s 916us/step - loss: 0.0843 - acc: 0.9835 - val_loss: 0.4083 - val_acc: 0.9343\n",
      "Epoch 136/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 0.0825 - acc: 0.9812 - val_loss: 0.4088 - val_acc: 0.9296\n",
      "Epoch 137/150\n",
      "850/850 [==============================] - 1s 901us/step - loss: 0.0872 - acc: 0.9824 - val_loss: 0.4083 - val_acc: 0.9296\n",
      "Epoch 138/150\n",
      "850/850 [==============================] - 1s 926us/step - loss: 0.0839 - acc: 0.9812 - val_loss: 0.4109 - val_acc: 0.9343\n",
      "Epoch 139/150\n",
      "850/850 [==============================] - 1s 911us/step - loss: 0.0857 - acc: 0.9776 - val_loss: 0.4105 - val_acc: 0.9343\n",
      "Epoch 140/150\n",
      "850/850 [==============================] - 1s 904us/step - loss: 0.0852 - acc: 0.9812 - val_loss: 0.4111 - val_acc: 0.9343\n",
      "Epoch 141/150\n",
      "850/850 [==============================] - 1s 905us/step - loss: 0.0841 - acc: 0.9753 - val_loss: 0.4112 - val_acc: 0.9296\n",
      "Epoch 142/150\n",
      "850/850 [==============================] - 1s 903us/step - loss: 0.0863 - acc: 0.9776 - val_loss: 0.4120 - val_acc: 0.9249\n",
      "Epoch 143/150\n",
      "850/850 [==============================] - 1s 904us/step - loss: 0.0779 - acc: 0.9812 - val_loss: 0.4124 - val_acc: 0.9249\n",
      "Epoch 144/150\n",
      "850/850 [==============================] - 1s 909us/step - loss: 0.0781 - acc: 0.9812 - val_loss: 0.4127 - val_acc: 0.9249\n",
      "Epoch 145/150\n",
      "850/850 [==============================] - 1s 898us/step - loss: 0.0758 - acc: 0.9812 - val_loss: 0.4136 - val_acc: 0.9296\n",
      "Epoch 146/150\n",
      "850/850 [==============================] - 1s 892us/step - loss: 0.0748 - acc: 0.9824 - val_loss: 0.4129 - val_acc: 0.9296\n",
      "Epoch 147/150\n",
      "850/850 [==============================] - 1s 910us/step - loss: 0.0728 - acc: 0.9824 - val_loss: 0.4135 - val_acc: 0.9249\n",
      "Epoch 148/150\n",
      "850/850 [==============================] - 1s 905us/step - loss: 0.0736 - acc: 0.9800 - val_loss: 0.4147 - val_acc: 0.9249\n",
      "Epoch 149/150\n",
      "850/850 [==============================] - 1s 919us/step - loss: 0.0721 - acc: 0.9835 - val_loss: 0.4149 - val_acc: 0.9296\n",
      "Epoch 150/150\n",
      "850/850 [==============================] - 1s 907us/step - loss: 0.0715 - acc: 0.9835 - val_loss: 0.4145 - val_acc: 0.9249\n"
     ]
    }
   ],
   "source": [
    "# Compile model. with Adam Optimizer and learning rate 0.0001 which gives good results for this model\n",
    "Adam = adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history=model.fit(np.array(train_x), np.array(train_y), epochs=150, batch_size=8,validation_data=(val_x,val_y), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_train = history.history['acc']\n",
    "loss_val = history.history['val_acc']\n",
    "epochs = range(1, len(loss_train) + 1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1, len(loss_train) + 1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.49%\n",
      "F1 Score: 85.78%\n",
      "Precision Score: 86.97%\n",
      "Recall Score: 86.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "pred = model.predict(val_x)\n",
    "predicted=np.argmax(pred, axis=1)\n",
    "report=classification_report(np.argmax(val_y, axis=1),predicted)\n",
    "\n",
    "result = model.evaluate(val_x,val_y, verbose=0)\n",
    "#res=np.argmax(result, axis=1)\n",
    "f1=f1_score(np.argmax(val_y, axis=1),predicted,average=\"macro\")\n",
    "precision=precision_score(np.argmax(val_y, axis=1),predicted,average=\"macro\")\n",
    "recall=recall_score(np.argmax(val_y, axis=1),predicted,average=\"macro\")\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (result[1]*100))\n",
    "\n",
    "#y_pred = model.predict(testx)\n",
    "print(\"F1 Score: %.2f%%\" % (f1*100))\n",
    "print(\"Precision Score: %.2f%%\" % (precision*100)) \n",
    "print(\"Recall Score: %.2f%%\" % (recall*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       0.67      1.00      0.80         4\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       1.00      1.00      1.00         3\n",
      "         10       1.00      1.00      1.00         3\n",
      "         11       1.00      1.00      1.00         3\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       1.00      1.00      1.00         3\n",
      "         15       1.00      1.00      1.00         1\n",
      "         17       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         5\n",
      "         22       0.00      0.00      0.00         0\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      0.67      0.80         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      1.00      1.00         5\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         1\n",
      "         34       1.00      1.00      1.00         3\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         3\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         1\n",
      "         40       1.00      1.00      1.00         7\n",
      "         41       0.50      1.00      0.67         1\n",
      "         42       1.00      1.00      1.00         2\n",
      "         43       1.00      1.00      1.00         1\n",
      "         44       1.00      1.00      1.00         3\n",
      "         47       1.00      1.00      1.00         2\n",
      "         48       1.00      1.00      1.00         2\n",
      "         49       1.00      1.00      1.00         1\n",
      "         50       1.00      1.00      1.00         4\n",
      "         51       1.00      1.00      1.00         3\n",
      "         52       0.00      0.00      0.00         0\n",
      "         53       1.00      1.00      1.00         1\n",
      "         54       1.00      1.00      1.00         1\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       1.00      1.00      1.00         2\n",
      "         57       1.00      1.00      1.00         3\n",
      "         58       1.00      1.00      1.00         2\n",
      "         60       1.00      1.00      1.00         1\n",
      "         61       1.00      1.00      1.00         5\n",
      "         62       1.00      1.00      1.00         1\n",
      "         63       1.00      1.00      1.00         2\n",
      "         64       1.00      1.00      1.00         2\n",
      "         66       1.00      0.50      0.67         2\n",
      "         67       1.00      1.00      1.00         3\n",
      "         70       1.00      1.00      1.00         2\n",
      "         71       1.00      1.00      1.00         1\n",
      "         72       0.86      1.00      0.92         6\n",
      "         73       1.00      1.00      1.00         3\n",
      "         75       1.00      1.00      1.00         3\n",
      "         78       1.00      1.00      1.00         1\n",
      "         79       1.00      1.00      1.00         3\n",
      "         80       0.00      0.00      0.00         0\n",
      "         81       1.00      1.00      1.00         3\n",
      "         82       1.00      1.00      1.00         3\n",
      "         84       0.83      1.00      0.91         5\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       0.50      1.00      0.67         1\n",
      "         90       1.00      1.00      1.00         4\n",
      "         91       1.00      1.00      1.00         2\n",
      "         92       1.00      1.00      1.00         1\n",
      "         93       1.00      0.67      0.80         3\n",
      "         94       1.00      1.00      1.00         1\n",
      "         95       1.00      1.00      1.00         4\n",
      "         96       1.00      1.00      1.00         1\n",
      "         97       1.00      1.00      1.00         4\n",
      "         98       1.00      1.00      1.00         1\n",
      "         99       1.00      1.00      1.00         1\n",
      "        100       1.00      1.00      1.00         4\n",
      "        101       1.00      1.00      1.00         1\n",
      "        102       1.00      1.00      1.00         2\n",
      "        103       1.00      1.00      1.00         4\n",
      "        105       1.00      1.00      1.00         6\n",
      "        106       1.00      1.00      1.00         1\n",
      "        108       0.00      0.00      0.00         1\n",
      "        109       1.00      1.00      1.00         2\n",
      "        110       1.00      1.00      1.00         4\n",
      "        111       1.00      1.00      1.00         1\n",
      "        112       1.00      1.00      1.00         2\n",
      "        113       1.00      1.00      1.00         3\n",
      "        114       0.80      1.00      0.89         4\n",
      "        116       1.00      1.00      1.00         2\n",
      "        118       0.00      0.00      0.00         1\n",
      "        119       1.00      1.00      1.00         1\n",
      "        121       0.00      0.00      0.00         1\n",
      "        122       1.00      1.00      1.00         1\n",
      "        124       0.00      0.00      0.00         3\n",
      "        125       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.94      0.94      0.94       213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import amharic_keyboard as ak\n",
    "\n",
    "def transliterate(user_input):\n",
    "\ttrans_file = open('amTen.json','r',encoding='utf-8')\n",
    "\ttrans_data = json.loads(trans_file.read())\n",
    "\ttrans_file.close()\n",
    "\ttrans_data = eval(trans_data)\n",
    "\n",
    "\tcharacters = re.findall('\\w',user_input)\n",
    "\n",
    "\tfor char in characters:\n",
    "\t\t\n",
    "\t\tif char in trans_data:\n",
    "\t\t\tprint(char+' = '+trans_data[char])\n",
    "\t\t\tuser_input = re.sub(char,trans_data[char],user_input)\n",
    "\n",
    "\treturn user_input\n",
    "\n",
    "def steming(word):\n",
    "    print('\\nNormalize and transliterate...')\n",
    "    user_input = transliterate(word)\n",
    "    wrds=nltk.word_tokenize(user_input)\n",
    "    #data=[]\n",
    "    Data = [re.sub('^(yete|mii|m|me|mayt|ma|bale|yit|endeee|endee|endiiee|al|ye|y|mas|le|ke|end|be|sle)', '', w) for w in wrds]\n",
    "    #data.append(Data)\n",
    "    \n",
    "    Data = [re.sub('(ewu|wu|w|awee|m|ma|l|ne|ach|woch|eoch|bach|wach|ch|ku|k|ach|wal)$', '', w) for w in Data]\n",
    "    #data.append(Data)\n",
    "    recreate=\" \".join(Data)\n",
    "    print(ak.type(recreate))\n",
    "    return recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import amharic_keyboard as ak\n",
    "def transliterate(user_input):\n",
    "\ttrans_file = open('amTen.json','r',encoding='utf-8')\n",
    "\ttrans_data = json.loads(trans_file.read())\n",
    "\ttrans_file.close()\n",
    "\ttrans_data = eval(trans_data)\n",
    "\n",
    "\tcharacters = re.findall('\\w',user_input)\n",
    "\n",
    "\tfor char in characters:\n",
    "\t\t\n",
    "\t\tif char in trans_data:\n",
    "\t\t\tprint(char+' = '+trans_data[char])\n",
    "\t\t\tuser_input = re.sub(char,trans_data[char],user_input)\n",
    "\n",
    "\treturn user_input\n",
    "\n",
    "def stem(input1):\n",
    "\n",
    "\t# RULE 1 - Take input as it is\n",
    "\tprint(input1)\n",
    "\tcollection = [input1]\n",
    "\n",
    "\t# RULE 2 - Take out the right most suffix - From input 1\n",
    "\tinput2 = re.match(\"(.+)(ewu|wu|wi|awee|na|m|ma|l|ne|ach)\",input1)\n",
    "\tif input2:\n",
    "\t\tprint(input2.group(1)+'-'+input2.group(2)) \n",
    "\t\tinput2 = input2.group(1); \n",
    "\t\tcollection.append(input2)\n",
    "\telse:\n",
    "\t\tinput2 = input1\n",
    "\n",
    "\t# RULE 3 - Take out the inner most suffix\n",
    "\tinput3 = re.match('(.+)(eoch|bach|wach)',input2)\t\n",
    "\tinput3 = re.match('(.+)(ch|ku|k|ach|wal)',input2) if not input3 else input3\n",
    "\tif input3:\n",
    "\t\tprint(input3.group(1)+'-'+input3.group(2))\n",
    "\t\tinput3 = input3.group(1)\n",
    "\t\tcollection.append(input3)\n",
    "\telse:\n",
    "\t\tinput3 = input2\t\n",
    "\n",
    "\t# RULE 4 - Take out the most left prefix - From input 1\n",
    "\tinput4 = re.match('(yete|endeee|endei|al)(.+)',input1)\n",
    "\tinput4 = re.match('(ye|y|mas|l|ke|end|be|sle)(.+)',input1) if not input4 else input4\n",
    "\tif input4:\n",
    "\t\tprint(input4.group(1)+'-'+input4.group(2))\n",
    "\t\tinput4 = input4.group(2)\n",
    "\t\tcollection.append(input4)\n",
    "\telse:\n",
    "\t\tinput4 = input1\t\n",
    "\n",
    "\t# RULE 5 - Take out the right most suffix - From input 4\n",
    "\tinput5 = re.match('(.+)(ewu|wu|w|awei|na|m|ma|l|ne|che)',input4)\n",
    "\tif input5: \n",
    "\t\tprint(input5.group(1)+'-'+input5.group(2))\n",
    "\t\tinput5 = input5.group(1)\n",
    "\t\tcollection.append(input5)\n",
    "\telse:\n",
    "\t\tinput5 = input4\n",
    "\n",
    "\t# RULE 6 - Take out the inner most suffix - From input 4\n",
    "\tinput6 = re.match('(.+)(eoch|bache|wache)',input5)\t\n",
    "\tinput6 = re.match('(.+)(ch|ku|k|che|wal)',input5) if not input6 else input6\n",
    "\tif input6:\n",
    "\t\tprint(input6.group(1)+'-'+input6.group(2))\n",
    "\t\tinput6 = input6.group(1)\n",
    "\t\tcollection.append(input6)\n",
    "\telse:\n",
    "\t\tinput6 = input5\n",
    "\n",
    "\t# RULE 7 - Take out the inner most prefix - From input 1\n",
    "\tinput7 = re.match('(te|mii|m|me|mayt|ma|bale|yit)(.+)',input4)\n",
    "\tif input7:\n",
    "\t\tprint(input7.group(1)+'-'+input7.group(2))\n",
    "\t\tinput7 = input7.group(2)\n",
    "\t\tcollection.append(input7)\n",
    "\telse:\n",
    "\t\tinput7 = input4\n",
    "\n",
    "\t# RULE 8 - Take out the right most suffix - From input 7\n",
    "\tinput8 = re.match('(.+)(ewu|wu|w|awii|na|m|ma|l|ne)',input7)\n",
    "\tif input8: \n",
    "\t\tprint(input8.group(1)+'-'+input8.group(2)); \n",
    "\t\tinput8 = input8.group(1)\n",
    "\t\tcollection.append(input8)\n",
    "\telse: \n",
    "\t\tinput8 = input4\n",
    "\n",
    "\n",
    "\t# RULE 9 - Take out the innermost suffix - From input 8\n",
    "\tinput9 = re.match('(.+)([^eeiaeoeu])’?',input8)\n",
    "\tif input9:\n",
    "\t\tprint(input9.group(1)+'-'+input9.group(2)); \n",
    "\t\tinput9 = input9.group(1)\n",
    "\t\tcollection.append(input9)\n",
    "\telse:\n",
    "\t\tinput9 = input4\n",
    "\n",
    "\tprint(ak.type(collection))\n",
    "\tstemeddd=str(sorted(collection))\n",
    "\tprint(ak.type(min(stemeddd)))\n",
    "\treturn collection\n",
    "\n",
    "def disambuigate(stems):\n",
    "\tdictionary = open('amh_lex_dic.trans.txt','r',encoding='utf-8')\n",
    "\tlexical_data = dictionary.read()\n",
    "\tdictionary.close()\n",
    "\n",
    "\tmatch = None\n",
    "\tstring_size = 0\n",
    "\tfor stem in stems:\n",
    "\t\ttemp = re.search('('+stem+') {(.+)}',lexical_data)\n",
    "\t\tif temp:\n",
    "\t\t\tprint(temp.group(1))\n",
    "\t\t\tif(len(stem) > string_size):\n",
    "\t\t\t\tstring_size = len(stem)\n",
    "\t\t\t\tmatch = temp\n",
    "\t\telse:\n",
    "\t\t\t# Rule 10\n",
    "\t\t\tstem = re.match(r'(.+)[īaou]\\b',stem)\n",
    "\t\t\tif stem:\n",
    "\t\t\t\tstems.append(re.sub(r'(.+)[īaou]\\b',r'\\1e',stem.group()))\n",
    "\t\t\t\tstems.append(re.sub(r'(.+)[īaou]\\b',r'\\1i',stem.group()))\n",
    "\n",
    "\treturn match\n",
    "\n",
    "def main():\n",
    "\tuser_input = input(\"Input an Amharic Word to be stemmed: \")\n",
    "\t\n",
    "\tprint('\\nNormalize and transliterate...')\n",
    "\tuser_input = transliterate(user_input)\n",
    "\n",
    "\tprint('\\nStemming...')\n",
    "\tstems = stem(user_input)\n",
    "\n",
    "\tif (len(stems) > 1):\n",
    "\t\tprint('\\nDisambuigating...')\n",
    "\t\toutput = disambuigate(stems)\n",
    "\n",
    "\t\tif output:\n",
    "\t\t\tprint('\\n'+output.group())\n",
    "\t\telse:\n",
    "\t\t\tprint(ak.type(stems))\n",
    "\telse:\n",
    "\t\tprint(ak.type('\\n'+stems))\n",
    "main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "\tmodified_word_list=[word for word in text if not word  in ignore_words]\n",
    "\treturn modified_word_list\n",
    "\n",
    "def normalize(sentence):\n",
    "    text=sentence.replace('ኀ','ሀ').replace('ሐ','ሀ').replace('ሃ','ሀ').replace('ኃ','ሀ').replace('ሓ','ሀ').replace('ኁ','ሁ').replace('ሑ','ሁ').replace('ሒ','ሂ').replace('ኂ','ሂ').replace('ኄ','ሄ').replace('ሔ','ሄ').replace('ሕ','ህ').replace('ኅ','ህ').replace('ሖ','ሆ').replace('ኆ','ሆ').replace('ጸ','ፀ').replace('ጹ','ፁ').replace('ጺ','ፂ').replace('ጻ','ፃ').replace('ጼ','ፄ').replace('ጽ','ፅ').replace('ጾ','ፆ').replace('ቸ,','ቼ').replace('ሸ','ሼ').replace('የ','ዬ').replace('ዉ','ው').replace('ሓ','ሀ').replace('ሠ','ሰ').replace('ሡ','ሱ').replace('ሢ','ሲ').replace('ሣ','ሳ').replace('ሤ','ሴ').replace('ሥ','ስ').replace('ሦ','ሶ').replace('ዐ','አ').replace('ዑ','ኡ').replace('ዒ','ኢ').replace('ዓ','ኣ').replace('ዔ','ኤ').replace('ዕ','እ').replace('ዖ','ኦ')\n",
    "    text =sentence.replace('መካኒካል','ሜካኒካል').replace('ኣ','አ').replace('ኣው','አዎ').replace('አው','አዎ').replace('ኢንጂነሪንግ','ምህንድስና').replace('ሰፍትዌር','ሶፍትዌር').replace('ሲስተም','ስይስተም').replace('ከሚካል','ኬሚካል').replace('ደምወዝ','ደሞዝ').replace('ዶሞዝ','ደሞዝ').replace('አርኪተክቸር','አርክተክቸር').replace('ኢሌክትሪካል','ኤሌክትሪካል').replace('ኮምፒተር','ኮምፕዩተር').replace('ሳይነስ','ሳይንስ').replace('ኢንፎርመሽን','ኢንፎርሜሽን').replace('ኢንዱስትርያል','ኢንዳስትሪያል').replace('ኢንዱስትሪያል','ኢንዳስትሪያል').replace('መሃንዲስ','መሀንድስ')\n",
    "    return(text)\n",
    "    \n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words= normalize(sentence)\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words if word not in ignore_words]\n",
    "    return sentence_words\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_FAQ_ChatBot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "from keras.models import load_model\n",
    "model=load_model('model_FAQ_Chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    p = bow(sentence, words)\n",
    "    \n",
    "    d = len(p)\n",
    "    f = len(documents)-2\n",
    "    a = np.zeros([f, d])\n",
    "    tot = np.vstack((p,a))\n",
    "    \n",
    "    results = model.predict(tot)[0]\n",
    "    \n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    print('Result:',results)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print ('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return (random.choice(i['responses']))\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you: ሰላም\n",
      "found in bag: ሰላም\n",
      "Result: [('ሰላምታ', 0.996653)]\n",
      "FAQ Bot:  ሰላማት ምን ላግዝህ/ሽ\n",
      "you: ምሕንድስና ምንድ ነው\n",
      "Result: [('ጤንነት', 0.2891798), ('ሰላምታ', 0.27676126)]\n",
      "FAQ Bot:  ደህና ነኝ\n",
      "you: ሠላም\n",
      "Result: [('ጤንነት', 0.2891798), ('ሰላምታ', 0.27676126)]\n",
      "FAQ Bot:  አመሰግናለሁ ድህና ነኝ\n",
      "you: ቻው\n",
      "Result: [('ጤንነት', 0.2891798), ('ሰላምታ', 0.27676126)]\n"
     ]
    }
   ],
   "source": [
    "# Simple chat\n",
    "while 1:\n",
    "    question=input(\"you: \")\n",
    "    if question=='':\n",
    "        print(\"FAQ Bot: sorry u didnt enter any question that intends to me\")\n",
    "    if question=='bye':\n",
    "        print(\"FAQ Bot: \", response(question))\n",
    "        break\n",
    "    elif question==\"ቻው\":\n",
    "        response(question)\n",
    "        break\n",
    "    else:\n",
    "        print(\"FAQ Bot: \", response(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: ምህንድስና\n",
      "found in bag: ምንድ\n",
      "found in bag: ነው\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "['greeting', 'መርሃ ግብሮች ፕሮግራም', 'ማስጠንቀቅያ ውጤት', 'ሜካኒካል ምህንድስና ስትሪም ', 'ሜካኒካል ምህንድስና ትርጉም', 'ምህንድስና ሚሰራበት ቦታ', 'ምህንድስና ዲፓርትመንቶች', 'ምስጋና', 'ምዝገባ ችግር', 'ሰላምታ', 'ሲቪል ምህንድስና ስትሪም ', 'ሲቪል ምህንድስና ትርጉም', 'ሲቪል ምህንድስና ጉዳት', 'ሲቪል ኢንጂነሪንግ ምሰራበት', 'ስለ ሜካኒካል ምህንድስና እውቀት', 'ስለ ሲቪል ምህንድስና እውቀት', 'ስለ አርክተክቸር ምህንድስና እውቀት', 'ስለ አድቫይዘር በይበልጥ', 'ስለ ኢንዳስትሪያል ምህንድስና እውቀት', 'ስለ ኤሌክትሪካል ምህንድስና እውቀት', 'ስለ ኬሚካል ምህንድስና እውቀት', 'ሶፍትዌር ምህንድስና ስትሪም ', 'ሶፍትዌር ምህንድስና ትርጉም', 'በትምህርት ምክንያት መባረር', 'በፈተና ወቅት መታመም', 'ትምህርት መከታተል', 'ትርፍ ጊዜ', 'አላሟላም ውጤት', 'አርክተክቸር ምህንድስና ስትሪም ', 'አርክተክቸር ምህንድስና ትርጉም', 'አድቫይዘር', 'አድቫይዘር መመደብ', 'አድቫይዘር መቀየር', 'አድቫይዘር መገናኘት', 'ኢንዳስትሪያል ምህንድስና ስትሪም ', 'ኢንዳስትሪያል ምህንድስና ትርጉም', 'ኢንጂነሪንግ', 'ኢንጂነሪንግ ለመግባት', 'ኢንጂነሪንግ ዲፓርትመንቶች', 'ኢንፎርሜሽን ስይስተም ስትሪም ', 'ኢንፎርሜሽን ስይስተም ትርጉም', 'ኤሌክትሪካል ምህንድስና ስትሪም ', 'ኤሌክትሪካል ምህንድስና ትርጉም', 'ከዩኒቨርስቲ ወደ ዩኒቨርስቲ መቀየር', 'ኬሚካል ምህንድስና ስትሪም ', 'ኬሚካል ምህንድስና ትርጉም', 'ክሬዲት ሃወር', 'ኮምፕዩተር ሳይንስ ስትሪም ', 'ኮምፕዩተር ሳይንስ ትርጉም', 'ኮርስ መድገም', 'ኮርስ መጣልና መጨመር', 'ዊዝ ድረው', 'ውጤት ማየት', 'ዝርዝር ኣለመፈለግ', 'የሜካኒካል ምህንድስና ኮርሶች', 'የሜካኒካል ምህንድስና ጉዳት', 'የሜካኒካል ምህንድስና ጥቅሞች', 'የሜካኒካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የሜካኒካል ኢንጂነሪንግ ምሰራበት', 'የሜካኒካል ኢንጂነሪንግ ስራ ዕድል', 'የምህንድስና ጉዳት', 'የምህንድስና ጥቅሞች', 'የምዝገባ ሂደት', 'የሲቪል ምህንድስና ጥቅሞች', 'የሲቪል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የሲቪል ኢንጂነሪንግ ስራ ዕድል', 'የስራ ጊዜ', 'የሶፍትዌር ምህንድስና ምሰራበት', 'የሶፍትዌር ምህንድስና ሰራተኛ ደሞዝ', 'የሶፍትዌር ምህንድስና ስራ ዕድል', 'የሶፍትዌር ምህንድስና ኮርሶች', 'የሶፍትዌር ምህንድስና ጉዳት', 'የሶፍትዌር ምህንድስና ጥቅሞች', 'የተማሪዎች ጥቅማጥቅሞች', 'የነባር መሃንዲስ ደሞዝ', 'የአርክተክቸር ምህንድስና ኮርሶች', 'የአርክተክቸር ምህንድስና ጉዳት', 'የአርክተክቸር ምህንድስና ጥቅሞች', 'የአርክተክቸር ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የአርክተክቸር ኢንጂነሪንግ ምሰራበት', 'የአርክተክቸር ኢንጂነሪንግ ስራ ዕድል', 'የኢንዳስትሪያል ምህንድስና ምሰራበት', 'የኢንዳስትሪያል ምህንድስና ኮርሶች', 'የኢንዳስትሪያል ምህንድስና ጉዳት', 'የኢንዳስትሪያል ምህንድስና ጥቅሞች', 'የኢንዳስትሪያል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኢንዳስትሪያል ኢንጂነሪንግ ስራ ዕድል', 'የኢንፎርሜሽን ስይስተም ምሰራበት', 'የኢንፎርሜሽን ስይስተም ሰራተኛ ደሞዝ', 'የኢንፎርሜሽን ስይስተም ስራ ዕድል', 'የኢንፎርሜሽን ስይስተም ኮርሶች', 'የኢንፎርሜሽን ስይስተም ጉዳት', 'የኢንፎርሜሽን ስይስተም ጥቅሞች', 'የኤሌክትሪካል ምህንድስና ኮርሶች', 'የኤሌክትሪካል ምህንድስና ጉዳት', 'የኤሌክትሪካል ምህንድስና ጥቅሞች', 'የኤሌክትሪካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኤሌክትሪካል ኢንጂነሪንግ ምሰራበት', 'የኤሌክትሪካል ኢንጂነሪንግ ስራ ዕድል', 'የኬሚካል ምህንድስና ኮርሶች', 'የኬሚካል ምህንድስና ጉዳት', 'የኬሚካል ምህንድስና ጥቅሞች', 'የኬሚካል ኢንጂነሪንግ መሃንዲስ ደሞዝ', 'የኬሚካል ኢንጂነሪንግ ምሰራበት', 'የኬሚካል ኢንጂነሪንግ ስራ ዕድል', 'የኮምፕዩተር ሳይንስ ምሰራበት', 'የኮምፕዩተር ሳይንስ ሰራተኛ ደሞዝ', 'የኮምፕዩተር ሳይንስ ስራ ዕድል', 'የኮምፕዩተር ሳይንስ ኮርሶች', 'የኮምፕዩተር ሳይንስ ጉዳት', 'የኮምፕዩተር ሳይንስ ጥቅሞች', 'የዊዝ ድረው ጊዜ', 'የጀማሪ መሃንዲስ ደሞዝ', 'የግል አስተማሪ', 'የግዜ ሰሌዳ መቀየር', 'ደካማ ውጤት', 'ዲፓርትመንት ልውውጥ', 'ዳግም ምዝገባ', 'ግሬድ', 'ጠቅላላ እውቀት', 'ጤንነት', 'ፈተና ማራዘም', 'ፈተና ኣለመፈተን', 'ፈተና ከተራዘመ', 'ፕሪ ኢንጂነሪንግ', 'ፕሪ ኢንጂነሪንግ ጥቅም']\n"
     ]
    }
   ],
   "source": [
    "p = bow(\"ምህንድስና ምንድ ነው\", words)\n",
    "print (p)\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.36419214e-06 6.16422369e-07 1.44417951e-04 9.21055180e-05\n",
      "  6.34275516e-03 1.01568185e-04 2.46931595e-04 1.32635790e-07\n",
      "  1.95012760e-07 3.21829521e-06 2.94591393e-02 1.20353810e-01\n",
      "  3.74924578e-03 6.67328248e-04 8.78381741e-07 1.55394577e-04\n",
      "  6.96349482e-04 1.19800288e-05 2.20637247e-07 1.99792112e-06\n",
      "  2.74065183e-04 1.23935956e-06 5.14971465e-03 1.29404607e-05\n",
      "  1.67659615e-04 1.07040892e-08 2.30615214e-03 6.10417163e-04\n",
      "  1.78306192e-01 3.54487158e-04 4.67563732e-05 3.53429550e-06\n",
      "  4.05568153e-06 8.98762810e-05 2.53378239e-04 2.99924225e-01\n",
      "  1.07025295e-01 4.19505704e-05 1.82087479e-05 1.79271126e-07\n",
      "  1.63686753e-08 7.59110029e-04 8.25413663e-05 2.77996674e-06\n",
      "  2.13048793e-03 1.50790602e-01 1.35496961e-07 6.14651026e-06\n",
      "  1.47945536e-06 2.79879913e-07 1.61894990e-04 1.02216018e-06\n",
      "  6.69766587e-06 2.93237963e-06 5.00077419e-07 4.29734075e-03\n",
      "  2.85279825e-02 4.51990473e-07 1.89708567e-06 1.23821839e-04\n",
      "  8.19700072e-04 2.24519434e-04 4.33900533e-03 2.15133373e-02\n",
      "  9.98450446e-07 3.73520935e-03 2.75175273e-03 1.23507953e-05\n",
      "  3.55266454e-03 1.88191134e-08 8.91010188e-07 7.44898716e-05\n",
      "  1.97938934e-05 3.76695767e-04 1.09910188e-05 9.57327647e-05\n",
      "  3.63567355e-03 2.38207940e-04 5.96859354e-06 7.93642612e-05\n",
      "  2.66442454e-04 1.87595069e-05 1.71195206e-05 6.46682864e-04\n",
      "  5.28299948e-04 9.98936230e-05 2.85472304e-08 1.03684679e-08\n",
      "  1.07598999e-06 6.15473397e-08 5.12866372e-09 2.37950317e-08\n",
      "  1.97655950e-07 2.43764789e-05 2.94529740e-03 8.05702584e-04\n",
      "  3.30975945e-06 6.08384994e-07 3.37372581e-03 2.04656862e-06\n",
      "  7.20618933e-04 7.37476454e-04 5.39450548e-06 9.30151509e-05\n",
      "  1.69906963e-03 9.29897368e-08 4.08604858e-04 2.75392097e-07\n",
      "  1.77135497e-08 2.42782130e-06 5.10177529e-07 6.71078226e-07\n",
      "  9.31141528e-08 1.66383487e-07 1.53144374e-05 4.24431273e-05\n",
      "  1.37618912e-07 3.22337903e-04 2.36327242e-06 8.91170384e-06\n",
      "  1.75867935e-05 1.10894362e-04 9.62043778e-05 1.82882638e-03\n",
      "  8.80069638e-05 5.83384390e-05]]\n"
     ]
    }
   ],
   "source": [
    "inputvar = pd.DataFrame([p], dtype=float, index=['input'])\n",
    "\n",
    "print(model.predict(inputvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"katana-assistant-data.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'module'>: attribute lookup module on builtins failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-386d60c4ae59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save model to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"katana-assistant-model.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'module'>: attribute lookup module on builtins failed"
     ]
    }
   ],
   "source": [
    "# save model to file\n",
    "pickle.dump(model, open(\"katana-assistant-model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1bff3f5f4e9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'katana-assistant-model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# Use pickle to load in the pre-trained model\n",
    "global graph\n",
    "graph = tf.get_default_graph()\n",
    "with open('katana-assistant-model.pkl','rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    # filter out predictions below a threshold, and provide intent index\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    # return tuple of intent and probability\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "@app.route(\"/katana-ml/api/v1.0/assistant\", methods=['POST'])\n",
    "def classify():\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    sentence = request.json['sentence']\n",
    "    \n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    # return tuple of intent and probability\n",
    "    \n",
    "    response = jsonify(return_list)\n",
    "    return response\n",
    "\n",
    "\n",
    "# running REST interface, port=5000 for direct test, port=5001 for deployment from PM2\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, host='0.0.0.0', port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
